<!DOCTYPE html PUBLIC '-//W3C//DTD XHTML 1.0 Strict//EN'
    'http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd'>
<html xmlns='http://www.w3.org/1999/xhtml' xml:lang='en' lang='en'>
  <head>
    <link rel='stylesheet' href='style.css' type='text/css' />
    <title>
      command line fu
    </title>
  </head>
  <body>
    <div class='terminal'>
      <div class='author'>
        syssyphus
      </div>
      <div class='summary'>
        Find Duplicate Files (based on size first, then MD5 hash)
      </div>
      <div class='command'>
        find -not -empty -type f -printf "%s\n" | sort -rn | uniq -d | xargs -I{} -n1 find -type f -size {}c -print0 | xargs -0 md5sum | sort | uniq -w32 --all-repeated=separate
      </div>
      <div class='desc'>
        <p>
          This dup finder saves time by comparing size first, then md5sum, it doesn't delete anything, just lists them.
        </p>
      </div>
    </div>
    <div class='terminal'>
      <div class='author'>
        infinull
      </div>
      <div class='summary'>
        <a href="/commands/view/2863/find-duplicate-files-based-on-md5-hash" title="Find out what others think of this command">Find Duplicate Files (based on MD5 hash)</a>
      </div>
      <div class='command'>
        find -type f -exec md5sum '{}' ';' | sort | uniq --all-repeated=separate -w 33 | cut -c 35-
      </div>
      <div class='desc'>
        <p>
          Calculates md5 sum of files. sort (required for uniq to work). uniq based on only the hash. use cut ro remove the hash from the result.
        </p>
      </div>
    </div>
    <div class='terminal'>
      <div class='author'>
        Vilemirth
      </div>
      <div class='summary'>
        <a href="/commands/view/7930/find-duplicate-files-based-on-size-first-then-md5-hash" title="Find out what others think of this command">Find Duplicate Files (based on size first, then MD5 hash)</a>
      </div>
      <div class='command'>
        fdupes -r .
      </div>
      <div class='desc'>
        <p>
          If you have the fdupes command, you'll save a lot of typing. It can do recursive searches (-r,-R) and it allows you to interactively select which of the duplicate files found you wish to keep or delete.
        </p>
      </div>
    </div>
    <div class='terminal'>
      <div class='author'>
        2chg
      </div>
      <div class='summary'>
        <a href="/commands/view/4701/find-duplicate-files-excluding-.svn-directories-based-on-size-first-then-md5-hash" title="Find out what others think of this command">Find Duplicate Files, excluding .svn-directories (based on size first, then MD5 hash)</a>
      </div>
      <div class='command'>
        find -type d -name ".svn" -prune -o -not -empty -type f -printf "%s\n" | sort -rn | uniq -d | xargs -I{} -n1 find -type d -name ".svn" -prune -o -type f -size {}c -print0 | xargs -0 md5sum | sort | uniq -w32 --all-repeated=separate
      </div>
      <div class='sample'>
        <pre>
[...]
f2e6bb247f110dcab63b4d38ff7b2dee  ./themes/darkblue_orange/img/b_relations.png
f2e6bb247f110dcab63b4d38ff7b2dee  ./themes/original/img/b_relations.png

f5309bd2a2fc5e512a0cc38ac6f10c09  ./themes/darkblue_orange/img/b_deltbl.png
f5309bd2a2fc5e512a0cc38ac6f10c09  ./themes/original/img/b_deltbl.png

f60bfbb7ce218a55650c1abbbbee06ae  ./themes/darkblue_orange/img/s_lang.png
f60bfbb7ce218a55650c1abbbbee06ae  ./themes/original/img/s_lang.png

f63a5ad833147eeb94adb4496ddbec41  ./themes/darkblue_orange/img/s_theme.png
f63a5ad833147eeb94adb4496ddbec41  ./themes/original/img/s_theme.png

f6ae61146ce3de8fa11b9e84e086bd04  ./themes/darkblue_orange/img/bd_drop.png
f6ae61146ce3de8fa11b9e84e086bd04  ./themes/original/img/bd_drop.png

f95d66c11bfed9198d13a278269c32b2  ./themes/darkblue_orange/img/s_loggoff.png
f95d66c11bfed9198d13a278269c32b2  ./themes/original/img/s_loggoff.png
[...]
</pre>
      </div>
      <div class='desc'>
        <p>
          Improvement of the command "Find Duplicate Files (based on size first, then MD5 hash)" when searching for duplicate files in a directory containing a subversion working copy. This way the (multiple dupicates) in the meta-information directories are ignored.
        </p>
        <p>
          Can easily be adopted for other VCS as well. For CVS i.e. change ".svn" into ".csv":
        </p><code>find -type d -name ".csv" -prune -o -not -empty -type f -printf "%s\n" | sort -rn | uniq -d | xargs -I{} -n1 find -type d -name ".csv" -prune -o -type f -size {}c -print0 | xargs -0 md5sum | sort | uniq -w32 --all-repeated=separate</code>
      </div>
    </div>
    <div class='terminal'>
      <div class='author'>
        unixmonkey8046
      </div>
      <div class='summary'>
        <a href="/commands/view/4697/find-duplicate-files-based-on-size-first-then-md5-hash" title="Find out what others think of this command">Find Duplicate Files (based on size first, then MD5 hash)</a>
      </div>
      <div class='command'>
        find -not -empty -type f -printf "%s\n" | sort | uniq -d | parallel find -type f -size {}c | parallel md5sum | sort | uniq -w32 --all-repeated=separate
      </div>
      <div class='desc'>
        <p>
          A bit shorter and parallelized. Depending on the speed of your cpu and your disk this may run faster.
        </p>
        <p>
          Parallel is from https://savannah.nongnu.org/projects/parallel/
        </p>
      </div>
    </div>
    <div class='comment'>
      <div class='author'>
        bwoodacre
      </div>
      <div class='text'>
        <p>
          As an alternative, check out <a href="http://www.pixelbeat.org/fslint/" rel="nofollow">http://www.pixelbeat.org/fslint/</a> in case you don't mind using a GUI for this. It gives you the option of hard linking the duplicate files and doing other lint-y tasks. Available as package 'fslint' at least in debian/ubuntu.
        </p>
      </div>
    </div>
    <div class='comment'>
      <div class='author'>
        pixelbeat
      </div>
      <div class='text'>
        <p>
          Thanks for the FSlint reference. Note fslint uses much the same mechanism underneath and has a CLI mode.
        </p>
        <p>
          <a href="http://fslint.googlecode.com/svn/trunk/fslint/findup" rel="nofollow">http://fslint.googlecode.com/svn/trunk/fslint/findup</a>
        </p>
      </div>
    </div>
    <div class='comment'>
      <div class='author'>
        dakunesu
      </div>
      <div class='text'>
        <p>
          awsome, much faster then fdupes.
        </p>
      </div>
    </div>
    <div class='comment'>
      <div class='author'>
        dennisw
      </div>
      <div class='text'>
        <p>
          Isn't the -D redundant?
        </p>
      </div>
    </div>
    <div class='comment'>
      <div class='author'>
        syssyphus
      </div>
      <div class='text'>
        <p>
          yes it is... thanks for noticing, I fixed it.
        </p>
      </div>
    </div>
    <div class='comment'>
      <div class='author'>
        matthewbauer
      </div>
      <div class='text'>
        <p>
          How can you mass delete these files once they're found? (I'd like to keep one of them)
        </p>
      </div>
    </div>
    <div class='comment'>
      <div class='author'>
        syssyphus
      </div>
      <div class='text'>
        <p>
          you might want to look at fdupes or fslint in order to help with hardlinking / deleting, etc... my command is really just a quick hack to list them.
        </p>
      </div>
    </div>
    <div class='comment'>
      <div class='author'>
        zabuch
      </div>
      <div class='text'>
        <p>
          There is also perfect match:
        </p>
        <p>
          <a href="http://pmatch.rubyforge.org/" rel="nofollow">http://pmatch.rubyforge.org/</a>
        </p>
        <p>
          That's especially if you are commandline fan.
        </p>
      </div>
    </div>
    <div class='comment'>
      <div class='author'>
        oernii3
      </div>
      <div class='text'>
        <p>
          Fantastic, man. this is truly great.
        </p>
      </div>
    </div>
    <div class='comment'>
      <div class='author'>
        sahib
      </div>
      <div class='text'>
        <p>
          There is also rmlint:
        </p>
        <p>
          https://github.com/sahib/rmlint
        </p>
        <p>
          Example:
        </p>
        <p>
          rmlint [path] -GYX -v5
        </p>
        <p>
          + Gives you similiar results
        </p>
        <p>
          + you can pipe it directly to 'sh'
        </p>
        <p>
          + it's lots faster as additionally fingerprints are done and a few other tricks.
        </p>
        <p>
          + it has also other options ;-)
        </p>
      </div>
    </div>
  </body>
</html>
