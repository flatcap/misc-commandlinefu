<!DOCTYPE html PUBLIC '-//W3C//DTD XHTML 1.0 Strict//EN'
    'http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd'>
<html xmlns='http://www.w3.org/1999/xhtml' xml:lang='en' lang='en'>
  <head>
    <link rel='stylesheet' href='style.css' type='text/css' />
    <title>
      command line fu
    </title>
  </head>
  <body>
    <div class='terminal'>
      <div class='author'>
        atoponce
      </div>
      <div class='summary'>
        Expand shortened URLs
      </div>
      <div class='command'>
        expandurl() { wget -S $1 2&gt;&amp;1 | grep ^Location; }
      </div>
      <div class='sample'>
        <pre>
Location: http://is.gd/jAdSZ3 [following]
Location: https://wiki.ubuntu.com/UbuntuOpenWeek [following]
</pre>
      </div>
      <div class='desc'>
        <p>
          This shell function uses wget(1) to show what site a shortened URL is pointing to, even if there are many nested shortened URLs. This is a great way to test whether or not the shortened URL is sending you to a malicious site, or somewhere nasty that you don't want to visit. The sample output is from:
        </p><code>expandurl http://t.co/LDWqmtDM</code>
      </div>
    </div>
    <div class='terminal'>
      <div class='author'>
        atoponce
      </div>
      <div class='summary'>
        <a href="/commands/view/9515/expand-shortened-urls" title="Find out what others think of this command">Expand shortened URLs</a>
      </div>
      <div class='command'>
        expandurl() { curl -sIL $1 | grep ^Location; }
      </div>
      <div class='sample'>
        <pre>
Location: http://is.gd/jAdSZ3 [following]
Location: https://wiki.ubuntu.com/UbuntuOpenWeek [following]
</pre>
      </div>
      <div class='desc'>
        <p>
          curl(1) is more portable than wget(1) across Unices, so here is an alternative doing the same thing with greater portability. This shell function uses curl(1) to show what site a shortened URL is pointing to, even if there are many nested shortened URLs. This is a great way to test whether or not the shortened URL is sending you to a malicious site, or somewhere nasty that you don't want to visit. The sample output is from:
        </p><code>expandurl http://t.co/LDWqmtDM</code>
      </div>
    </div>
    <div class='terminal'>
      <div class='author'>
        defiantredpill
      </div>
      <div class='summary'>
        <a href="/commands/view/9517/expand-shortened-urls" title="Find out what others think of this command">Expand shortened URLs</a>
      </div>
      <div class='command'>
        expandurl() { curl -sIL $1 2&gt;&amp;1 | awk '/^Location/ {print $2}' | tail -n1; }
      </div>
      <div class='sample'>
        <pre>
https://wiki.ubuntu.com/UbuntuOpenWeek
</pre>
      </div>
      <div class='desc'>
        <p>
          This shell function uses curl(1) as it is more portable than wget(1) across Unices, to show what site a shortened URL is pointing to, even if there are many nested shortened URLs. It is a refinement to <a href="http://www.commandlinefu.com/commands/view/9515/expand-shortened-urls" rel="nofollow">www.commandlinefu.com/commands/view/9515/expand-shortened-urls</a> to make it better for use in scripts. Only displays final result.
        </p><code>expandurl http://t.co/LDWqmtDM</code>
      </div>
    </div>
    <div class='comment'>
      <div class='author'>
        linuxrawkstar
      </div>
      <div class='text'>
        <p>
          sweet!
        </p>
      </div>
    </div>
    <div class='comment'>
      <div class='author'>
        flatcap
      </div>
      <div class='text'>
        <p>
          Nice, however with bash, you'll need a ; at the end of the grep part.
        </p>
      </div>
    </div>
    <div class='comment'>
      <div class='author'>
        defiantredpill
      </div>
      <div class='text'>
        <p>
          Nice, But would like to see a version of this that only prints the last line and/or drops the "Location: " and " [following]" bits.
        </p>
      </div>
    </div>
    <div class='comment'>
      <div class='author'>
        atoponce
      </div>
      <div class='text'>
        <p>
          @flatcap updated. thx. simple missing typo. glad someone is paying attention
        </p>
        <p>
          @defiantredpill seems simple enough to use by replacing grep(1) with awk(1). submit an alternative!
        </p>
      </div>
    </div>
    <div class='comment'>
      <div class='author'>
        defiantredpill
      </div>
      <div class='text'>
        <p>
          @atoponce I forked your curl version instead, just waiting for a mod to look at it as it was my first command.
        </p>
      </div>
    </div>
    <div class='comment'>
      <div class='author'>
        wipu
      </div>
      <div class='text'>
        <p>
          The wget version not only prints locations, it also downloads.
        </p>
      </div>
    </div>
    <div class='comment'>
      <div class='author'>
        defiantredpill
      </div>
      <div class='text'>
        <p>
          expandurl() { curl -sIL $1 2&gt;&amp;1 | awk '/^Location/ {print $2}' | tail -n1; }
        </p>
      </div>
    </div>
  </body>
</html>
